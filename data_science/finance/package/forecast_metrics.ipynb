{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from iexfinance import get_historical_data\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score, confusion_matrix, r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly\n",
    "import timeit\n",
    "import random\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_iex_data(stock_list, start, end):\n",
    "    return_list = []\n",
    "    for i in stock_list:\n",
    "        df = pd.DataFrame(get_historical_data(i, start, end, output_format='pandas')).interpolate()\n",
    "        df['ticker'] = i\n",
    "        return_list.append(df)\n",
    "    return return_list\n",
    "\n",
    "def lstm_clean_data(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].reset_index().dropna()\n",
    "        data[i]['date'] = pd.to_datetime(data[i]['date'])\n",
    "        data[i] = data[i].set_index('date')\n",
    "        data[i]['Reg_Target'] = data[i]['close'].shift(-1)\n",
    "    return data\n",
    "\n",
    "def add_past(etf_list, times):\n",
    "    for i in range(len(etf_list)):\n",
    "        for n in times:\n",
    "            etf_list[i]['{}day return'.format(n)] = -etf_list[i]['close'].diff(periods=n).round(3)\n",
    "    return etf_list\n",
    "\n",
    "def lstm_time_test_split(X, n_past, date):\n",
    "    X = X.reset_index()\n",
    "    scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "    ticker = X['ticker'].iloc[0]\n",
    "    x_train = X[X['date'] < date].drop(columns=['date', 'Reg_Target', 'ticker', '1day return', '5day return', '21day return', '252day return'])\n",
    "    scaler.fit(x_train)\n",
    "    x_test = X[X['date'] >= date].drop(columns=['date', 'Reg_Target', 'ticker', '1day return', '5day return', '21day return', '252day return'])[:-1]\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_train = np.reshape(x_train,(x_train.shape[0], n_past, x_train.shape[1]))\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0], n_past, x_test.shape[1]))\n",
    "    y_train = np.array(X[X['date'] < date]['Reg_Target'].drop(columns='date')).ravel().astype('float').reshape(-1,1)\n",
    "    y_scaler.fit(y_train)\n",
    "    y_train = y_scaler.transform(y_train)\n",
    "    y_test = np.array(X[X['date'] >= date]['Reg_Target'].drop(columns='date')).ravel().astype('float')[:-1].reshape(-1,1)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "    x_holdout = X[X['date'] >= date].drop(columns=['date', 'Reg_Target', 'ticker', '1day return', '5day return', '21day return', '252day return'])[-1:]\n",
    "    x_holdout = scaler.transform(x_holdout)\n",
    "    x_holdout = np.reshape(x_holdout,(x_holdout.shape[0], n_past, x_holdout.shape[1]))\n",
    "#     y_test = scaler.transform(y_test)\n",
    "    return ticker, x_train, x_test, x_holdout, y_train, y_test, scaler, y_scaler\n",
    "\n",
    "def build_step_model(x_train, y_train, epoc):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(x_train, y_train, epochs=epoc, batch_size=64, validation_split=.1, verbose=2,shuffle=False)\n",
    "    return model, history\n",
    "\n",
    "def yield_preds(model, scaler, x_test, x_holdout, y_test):\n",
    "    yhat = model.predict(x_test)\n",
    "    preds = scaler.inverse_transform(yhat)\n",
    "    true = scaler.inverse_transform(y_test)\n",
    "    today = model.predict(x_holdout)\n",
    "    today_pred = scaler.inverse_transform(today)\n",
    "    return preds, today_pred\n",
    "\n",
    "def run_all_lstms(data, split, epoc):\n",
    "    out = pd.DataFrame()\n",
    "    tomorrow = pd.DataFrame()\n",
    "    start = timeit.default_timer()\n",
    "    for i in range(len(data)):\n",
    "        ticker, x_train, x_test, x_holdout, y_train, y_test, scaler, y_scaler = lstm_time_test_split(data[i], 1, split)\n",
    "        print('Model #: {}'.format(i))\n",
    "        model, history = build_step_model(x_train, y_train, epoc)\n",
    "        preds, future = yield_preds(model, y_scaler, x_test, x_holdout, y_test)\n",
    "        out[ticker] = preds.flatten()\n",
    "        tomorrow[ticker] = future.flatten()\n",
    "    out = out.set_index(data[0][-len(out):].index)\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)\n",
    "    return out, tomorrow\n",
    "etf_list = ['SPY','IVV','VTI','VOO','QQQ','VEA','EFA','IEFA','VWO','AGG','IJH','IEMG','IWM','IJR','VTV','IWF','IWD','VUG','BND','LQD']\n",
    "data = get_iex_data(etf_list, None, None)\n",
    "clean_full = lstm_clean_data(data)\n",
    "data = add_past(clean_full, [1, 5, 21, 252])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(len(data)):\n",
    "    df[data[i]['ticker'].iloc[0]] = data[i]['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "naive = df.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #: 0\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 2s - loss: 0.1311 - val_loss: 0.4998\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0643 - val_loss: 0.2724\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0207 - val_loss: 0.0924\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0130 - val_loss: 0.0268\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0167 - val_loss: 0.0251\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0130 - val_loss: 0.0277\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0103 - val_loss: 0.0181\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0031 - val_loss: 7.1386e-04\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0024 - val_loss: 4.4506e-04\n",
      "Model #: 1\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 2s - loss: 0.1281 - val_loss: 0.5014\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0628 - val_loss: 0.2744\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0204 - val_loss: 0.0989\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0373\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0197 - val_loss: 0.0381\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0166 - val_loss: 0.0396\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0277\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0095 - val_loss: 0.0177\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Model #: 2\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.1392 - val_loss: 0.5234\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0718 - val_loss: 0.2936\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0216 - val_loss: 0.0997\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0112 - val_loss: 0.0244\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0158 - val_loss: 0.0223\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0295\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0093 - val_loss: 0.0207\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0072 - val_loss: 0.0120\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0032 - val_loss: 0.0015\n",
      "Model #: 3\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 2s - loss: 0.1359 - val_loss: 0.5253\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0725 - val_loss: 0.3064\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0251 - val_loss: 0.1151\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0123 - val_loss: 0.0314\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0168 - val_loss: 0.0240\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0283\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0105 - val_loss: 0.0206\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0078 - val_loss: 0.0111\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0027 - val_loss: 7.5450e-04\n",
      "Model #: 4\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.0990 - val_loss: 0.5226\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0538 - val_loss: 0.3271\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0237 - val_loss: 0.1589\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0164 - val_loss: 0.0709\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0180 - val_loss: 0.0500\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0164 - val_loss: 0.0476\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0122 - val_loss: 0.0352\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0086 - val_loss: 0.0203\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0063 - val_loss: 0.0108\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0023 - val_loss: 6.7386e-04\n",
      "Model #: 5\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.1814 - val_loss: 0.4444\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0988 - val_loss: 0.2407\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0306 - val_loss: 0.0676\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0111 - val_loss: 0.0078\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0086\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0174\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Model #: 6\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.1749 - val_loss: 0.4265\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0932 - val_loss: 0.2253\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0269 - val_loss: 0.0592\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0201\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Model #: 7\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.1828 - val_loss: 0.4613\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.1047 - val_loss: 0.2644\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0349 - val_loss: 0.0827\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0059\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0039 - val_loss: 0.0012\n",
      "Model #: 8\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.2004 - val_loss: 0.3453\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.1114 - val_loss: 0.1782\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0347 - val_loss: 0.0414\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0130 - val_loss: 0.0031\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0184 - val_loss: 0.0050\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0077 - val_loss: 0.0033\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0040 - val_loss: 0.0014\n",
      "Model #: 9\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.3411 - val_loss: 0.4311\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.2299 - val_loss: 0.2605\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0979 - val_loss: 0.0737\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0011\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0211 - val_loss: 0.0019\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0185 - val_loss: 0.0032\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0017\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0113 - val_loss: 9.1659e-04\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0107 - val_loss: 9.8781e-04\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0086 - val_loss: 7.9795e-04\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0077 - val_loss: 7.1691e-04\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0070 - val_loss: 8.5719e-04\n",
      "Model #: 10\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.1661 - val_loss: 0.5421\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0777 - val_loss: 0.2712\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0171 - val_loss: 0.0667\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0126 - val_loss: 0.0165\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0285\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0318\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0103 - val_loss: 0.0199\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Model #: 11\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.1731 - val_loss: 0.3614\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0966 - val_loss: 0.1939\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0321 - val_loss: 0.0518\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0104 - val_loss: 0.0042\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0153 - val_loss: 0.0038\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0126 - val_loss: 0.0094\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0071 - val_loss: 0.0027\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0042 - val_loss: 9.1757e-04\n",
      "Model #: 12\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 4s - loss: 0.1719 - val_loss: 0.6294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      " - 0s - loss: 0.0986 - val_loss: 0.3883\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0313 - val_loss: 0.1407\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0103 - val_loss: 0.0319\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0162 - val_loss: 0.0331\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0459\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0096 - val_loss: 0.0316\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0081 - val_loss: 0.0180\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0056 - val_loss: 0.0090\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Model #: 13\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 5s - loss: 0.1198 - val_loss: 0.5225\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0563 - val_loss: 0.2816\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0900\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0117 - val_loss: 0.0339\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0445\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0119 - val_loss: 0.0467\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0091 - val_loss: 0.0319\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0077 - val_loss: 0.0203\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0067 - val_loss: 0.0135\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0033 - val_loss: 0.0023\n",
      "Model #: 14\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 5s - loss: 0.1687 - val_loss: 0.5465\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0970 - val_loss: 0.3283\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0356 - val_loss: 0.1214\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0255\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0195 - val_loss: 0.0171\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0187\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0044 - val_loss: 0.0013\n",
      "Model #: 15\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 5s - loss: 0.0988 - val_loss: 0.5016\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0518 - val_loss: 0.2994\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0195 - val_loss: 0.1305\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0506\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0358\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0124 - val_loss: 0.0345\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0088 - val_loss: 0.0233\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0064 - val_loss: 0.0116\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0022 - val_loss: 8.2761e-04\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0021 - val_loss: 5.0732e-04\n",
      "Model #: 16\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 5s - loss: 0.2090 - val_loss: 0.5613\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.1284 - val_loss: 0.3536\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0495 - val_loss: 0.1348\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0123 - val_loss: 0.0215\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0170 - val_loss: 0.0229\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0201\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0049 - val_loss: 0.0025\n",
      "Model #: 17\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 5s - loss: 0.1126 - val_loss: 0.5055\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.0545 - val_loss: 0.2835\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0174 - val_loss: 0.1048\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0117 - val_loss: 0.0353\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0153 - val_loss: 0.0327\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0124 - val_loss: 0.0358\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0093 - val_loss: 0.0244\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0066 - val_loss: 0.0132\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0055 - val_loss: 0.0085\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0025 - val_loss: 6.6848e-04\n",
      "Model #: 18\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 6s - loss: 0.2901 - val_loss: 0.3055\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.1551 - val_loss: 0.1268\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0372 - val_loss: 0.0085\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0046\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0202 - val_loss: 9.9247e-04\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0158 - val_loss: 0.0023\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0114 - val_loss: 8.1129e-04\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0104 - val_loss: 7.7143e-04\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0092 - val_loss: 7.9167e-04\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0073 - val_loss: 7.0381e-04\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0069 - val_loss: 6.9768e-04\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0058 - val_loss: 5.7117e-04\n",
      "Model #: 19\n",
      "Train on 831 samples, validate on 93 samples\n",
      "Epoch 1/12\n",
      " - 6s - loss: 0.2661 - val_loss: 0.3566\n",
      "Epoch 2/12\n",
      " - 0s - loss: 0.1590 - val_loss: 0.1845\n",
      "Epoch 3/12\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0344\n",
      "Epoch 4/12\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0013\n",
      "Epoch 5/12\n",
      " - 0s - loss: 0.0212 - val_loss: 8.1746e-04\n",
      "Epoch 6/12\n",
      " - 0s - loss: 0.0168 - val_loss: 0.0035\n",
      "Epoch 7/12\n",
      " - 0s - loss: 0.0127 - val_loss: 0.0017\n",
      "Epoch 8/12\n",
      " - 0s - loss: 0.0109 - val_loss: 9.1501e-04\n",
      "Epoch 9/12\n",
      " - 0s - loss: 0.0092 - val_loss: 9.5071e-04\n",
      "Epoch 10/12\n",
      " - 0s - loss: 0.0076 - val_loss: 9.2243e-04\n",
      "Epoch 11/12\n",
      " - 0s - loss: 0.0061 - val_loss: 6.5253e-04\n",
      "Epoch 12/12\n",
      " - 0s - loss: 0.0054 - val_loss: 7.0191e-04\n",
      "Time:  170.91788853799994\n"
     ]
    }
   ],
   "source": [
    "mapframe_preds, future_preds = run_all_lstms(data, '09-2018', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Forecasting with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e7cbfad5e54d54b9ef360e74e79f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='ETFs', options=('SPY', 'IVV', 'VTI', 'VOO', 'QQQ', 'VEA', 'EFA', 'IEFA', 'VWO', 'AGG', 'IJH', 'IEMG', 'IWM', 'IJR', 'VTV', 'IWF', 'IWD', 'VUG', 'BND', 'LQD'), value='SPY'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lstm_plot>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lstm_plot(ETFs):\n",
    "    nav_rmse = round(mean_squared_error(df[ETFs][mapframe_preds.index].values, naive[ETFs][mapframe_preds.index].values),3)\n",
    "    nav_mae = round(mean_absolute_error(df[ETFs][mapframe_preds.index].values, naive[ETFs][mapframe_preds.index].values),3)\n",
    "    nav_r2 = round(r2_score(df[ETFs][mapframe_preds.index].values, naive[ETFs][mapframe_preds.index].values),3)\n",
    "    rmse = round(mean_squared_error(df[ETFs][mapframe_preds.index].values, mapframe_preds[ETFs].values),3)\n",
    "    mae = round(mean_absolute_error(df[ETFs][mapframe_preds.index].values, mapframe_preds[ETFs].values),3)\n",
    "    r2 = round(r2_score(df[ETFs][mapframe_preds.index].values, mapframe_preds[ETFs].values),3)\n",
    "    true = go.Scatter(x=df.index, y=df[ETFs].values, mode = 'markers', name = 'True Value')\n",
    "    pred = go.Scatter(x=mapframe_preds.index, y=mapframe_preds[ETFs].values, mode = 'markers', name = 'Prediction')\n",
    "    nav = go.Scatter(x=mapframe_preds.index, y=naive[ETFs][mapframe_preds.index].values, mode = 'markers', name = 'Naive')\n",
    "    fake = go.Scatter(x=['07-2018'], y=df[ETFs].values, opacity = 0, name = '<br>Naive Metrics:<br>RMSE: {}<br>R-Squared: {}<br>MAE: {}<br><br>LSTM Metrics:<br>RMSE: {}<br>R-Squared: {}<br>MAE: {}'.format(nav_rmse,nav_mae,nav_r2,rmse,r2,mae))\n",
    "    trace = [true, nav, pred, fake]\n",
    "    layout = dict(title = \"{} Prices\".format(ETFs), xaxis = dict(range = ['2018-09-01','2018-10-04']), yaxis=dict(autorange=True, showgrid=True))\n",
    "    fig = dict(data=trace, layout=layout)\n",
    "    iplot(fig)\n",
    "interact(lstm_plot, ETFs=etf_list)"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
